{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMgrLSJRq/9fX+5X/MgbfWe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/EmanueleCeglia/PDF-Metadata-Extractor.git"
      ],
      "metadata": {
        "id": "MHIbcKwxLuKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PDF-Metadata-Extractor"
      ],
      "metadata": {
        "id": "Zf98MyPQL2Lz",
        "outputId": "453dc1e6-1f41-43f0-d7d4-748e133cb9e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PDF-Metadata-Extractor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "U0w-7EwSL9kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ghostscript -y"
      ],
      "metadata": {
        "id": "MNXmHnKO4x0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Dates"
      ],
      "metadata": {
        "id": "UiWcGaIttFL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from pdf_dates_finder import PDFDatesFinderSemanticSearch  #old method\n",
        "from pdf_dates_finder import PDFDatesFinderSpace   #new method\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Sl0zsSAz7gHE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download model"
      ],
      "metadata": {
        "id": "2zaVl7xYvVfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Open-Orca/OpenOrca-Platypus2-13B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Open-Orca/OpenOrca-Platypus2-13B\", device_map=\"auto\", load_in_8bit=True)"
      ],
      "metadata": {
        "id": "i6qxZyr37hMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_process_response_dates(text):\n",
        "    start_date_pattern = r\"Start date:\\s*([0-9]+[a-z]*\\s+[A-Z][a-z]+\\s+[0-9]{4})\"\n",
        "    end_date_pattern = r\"End date:\\s*([0-9]+[a-z]*\\s+[A-Z][a-z]+\\s+[0-9]{4})\"\n",
        "\n",
        "    start_date_match = re.search(start_date_pattern, text)\n",
        "    end_date_match = re.search(end_date_pattern, text)\n",
        "\n",
        "    result = {}\n",
        "    if start_date_match and end_date_match:\n",
        "        result['Start date'] = start_date_match.group(1)\n",
        "        result['End date'] = end_date_match.group(1)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    return result\n",
        "\n",
        "# second level filter\n",
        "def find_dates_regex(string):\n",
        "    pattern = r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b|\\b\\d{1,2} [A-Za-z]+ \\d{4}\\b|\\b\\d{1,2}(?:st|nd|rd|th)? [A-Za-z]+ \\d{4}\\b|\\b[A-Za-z]+ \\d{1,2}(?:st|nd|rd|th)? \\d{4}\\b'\n",
        "    dates = re.findall(pattern, string)\n",
        "    if len(dates) >= 2:\n",
        "        return f\"Start date: {dates[0]} End date: {dates[1]}\"\n",
        "    elif len(dates) == 1:\n",
        "        return f\"Start date: {dates[0]} End date: None\"\n",
        "    else:\n",
        "        return \"No dates found\""
      ],
      "metadata": {
        "id": "ihmEWA-uB9Ac"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dates extraction with OLD METHOD"
      ],
      "metadata": {
        "id": "titiBIbjBvUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insurances_folder_path = \"/content/PDF-Metadata-Extractor/Insurances\"\n",
        "\n",
        "extracted_dates = {}\n",
        "\n",
        "for root, dirs, files in os.walk(insurances_folder_path):\n",
        "    for file_name in tqdm(files):\n",
        "        full_file_path = os.path.join(root, file_name)\n",
        "\n",
        "        extraction = PDFDatesFinderSemanticSearch(full_file_path)\n",
        "        extraction.load_pdf()\n",
        "        extraction.process_text()\n",
        "        dates = extraction.find_dates()\n",
        "\n",
        "        for value in dates.values():\n",
        "          for phrase in value.values():\n",
        "            if len(phrase):\n",
        "              sentence = phrase[0]\n",
        "\n",
        "              prompt = \"Find start date and end date from the following sentence: \" + sentence\n",
        "              inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "              generate_ids = model.generate(inputs.input_ids, max_length=1000)\n",
        "              response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "              response = post_process_response_dates(response)\n",
        "\n",
        "              if response:\n",
        "                extracted_dates[str(file_name)] = response\n",
        "                print(str(file_name) + ' EXTRACTED!')\n",
        "              else:\n",
        "                print(str(file_name) + ' NOT FOUND!')"
      ],
      "metadata": {
        "id": "Ss5J8bpD_d8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dates extraction with NEW METHOD"
      ],
      "metadata": {
        "id": "jp-4QzmqarZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insurances_folder_path = \"/content/PDF-Metadata-Extractor/Insurances\"\n",
        "\n",
        "extracted_dates = {}\n",
        "\n",
        "for root, dirs, files in os.walk(insurances_folder_path):\n",
        "    for file_name in tqdm(files):\n",
        "        full_file_path = os.path.join(root, file_name)\n",
        "\n",
        "        extractor = PDFDatesFinderSpace(full_file_path)\n",
        "        pages, tables = extractor.extract_mytext()\n",
        "        paragraphs = [extractor.identify_paragraphs_space(page) for page in pages]\n",
        "        #print(paragraphs)\n",
        "\n",
        "        # keywords filter 1th level\n",
        "        check_kw = False\n",
        "        for phrase in paragraphs:\n",
        "          for sentence in phrase:\n",
        "            if re.search(r'\\bperiod\\b', sentence, re.IGNORECASE):\n",
        "              check_kw = True\n",
        "\n",
        "        if check_kw:\n",
        "          # Use a list comprehension with regex to keep only the phrases that contain the word \"period\" (case-insensitive)\n",
        "          paragraphs = [sublist for sublist in paragraphs if any(re.search(r'\\bperiod\\b', phrase, re.IGNORECASE) for phrase in sublist)]\n",
        "\n",
        "          # Now, further filter each sublist to keep only the phrases that contain the word \"period\"\n",
        "          paragraphs = [[phrase for phrase in sublist if re.search(r'\\bperiod\\b', phrase, re.IGNORECASE)] for sublist in paragraphs]\n",
        "\n",
        "\n",
        "        responses = []\n",
        "        for phrase in paragraphs:\n",
        "          if len(phrase):\n",
        "            for sentence in phrase:\n",
        "              sentcence = sentence.replace(',', '')\n",
        "              prompt = \"Find start date and end date from the following sentence: \" + sentence\n",
        "              inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "              generate_ids = model.generate(inputs.input_ids, max_length=200)\n",
        "              response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "              response = post_process_response_dates(response)\n",
        "\n",
        "              if response:\n",
        "                  responses.append(response)\n",
        "                  #print(response)\n",
        "\n",
        "        if len(responses)==0:\n",
        "          # Parse with regex for prompt fails\n",
        "          for phrase in paragraphs:\n",
        "            if len(phrase):\n",
        "              if len(phrase)>1:\n",
        "                phrase = [' '.join(phrase)]\n",
        "              for sentence in phrase:\n",
        "                  sentence = sentence.replace(',','')\n",
        "                  response = find_dates_regex(sentence)\n",
        "                  responses.append(response)\n",
        "\n",
        "        if responses:\n",
        "          print(str(file_name) + ' EXTRACTED!')\n",
        "          extracted_dates[str(file_name)] = responses\n",
        "        else:\n",
        "          print(str(file_name) + ' NOT FOUND!')"
      ],
      "metadata": {
        "id": "5qIvItUGavzo",
        "outputId": "6bcc0716-08e3-4918-cdf6-e388f2596fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/31 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "  3%|▎         | 1/31 [01:02<31:06, 62.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_10.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "  6%|▋         | 2/31 [02:57<45:17, 93.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_5.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 10%|▉         | 3/31 [04:34<44:23, 95.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_2.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 13%|█▎        | 4/31 [08:03<1:03:04, 140.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_97.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 16%|█▌        | 5/31 [09:40<53:56, 124.49s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_67.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 19%|█▉        | 6/31 [10:53<44:33, 106.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_26.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 23%|██▎       | 7/31 [13:54<52:25, 131.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_40.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 26%|██▌       | 8/31 [15:28<45:46, 119.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_52.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 29%|██▉       | 9/31 [16:59<40:32, 110.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_100.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 32%|███▏      | 10/31 [19:18<41:43, 119.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_27.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 35%|███▌      | 11/31 [20:39<35:51, 107.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_24.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input length of input_ids is 268, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 225, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            " 39%|███▊      | 12/31 [21:50<30:29, 96.29s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_4.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 42%|████▏     | 13/31 [22:33<24:02, 80.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_30.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 244, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            " 45%|████▌     | 14/31 [23:37<21:20, 75.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_33.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 48%|████▊     | 15/31 [24:20<17:32, 65.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_29.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 52%|█████▏    | 16/31 [24:44<13:16, 53.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_79.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 55%|█████▍    | 17/31 [26:49<17:25, 74.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_56.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 58%|█████▊    | 18/31 [29:42<22:34, 104.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_92.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 270, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            " 61%|██████▏   | 19/31 [31:06<19:36, 98.02s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_32.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 65%|██████▍   | 20/31 [32:00<15:35, 85.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_1.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 68%|██████▊   | 21/31 [33:28<14:19, 85.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_69.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 225, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            " 71%|███████   | 22/31 [34:56<12:58, 86.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_64.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 74%|███████▍  | 23/31 [36:06<10:51, 81.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_35.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 77%|███████▋  | 24/31 [38:43<12:09, 104.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_8.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 81%|████████  | 25/31 [40:07<09:48, 98.12s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_20.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 84%|████████▍ | 26/31 [43:22<10:35, 127.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_9.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 87%|████████▋ | 27/31 [44:09<06:52, 103.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_13.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            " 90%|█████████ | 28/31 [46:42<05:54, 118.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_66.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 208, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            " 94%|█████████▎| 29/31 [49:03<04:09, 124.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_63.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 30/31 [49:30<01:35, 95.62s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_22.pdf NOT FOUND!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input length of input_ids is 300, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 31/31 [50:17<00:00, 97.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy_39.pdf EXTRACTED!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_dates"
      ],
      "metadata": {
        "id": "ceoYx4rcl3pS",
        "outputId": "134a61bf-a21d-4838-d641-ec606d8a73a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'policy_10.pdf': [{'Start date': '1st January 2022',\n",
              "   'End date': '31st December 2022'}],\n",
              " 'policy_5.pdf': [{'Start date': '01 November 2021',\n",
              "   'End date': '31 October 2022'},\n",
              "  {'Start date': '01 November 2021', 'End date': '31 October 2022'}],\n",
              " 'policy_2.pdf': ['Start date: 01 January 2021 End date: 31 December 2020'],\n",
              " 'policy_97.pdf': [{'Start date': '01 September 2021',\n",
              "   'End date': '31 August 2022'},\n",
              "  {'Start date': '01 September 2021', 'End date': '31 August 2022'}],\n",
              " 'policy_67.pdf': ['Start date: 31st October 2022 End date: 31st October 2023'],\n",
              " 'policy_26.pdf': [{'Start date': '1st November 2022',\n",
              "   'End date': '31st October 2023'}],\n",
              " 'policy_40.pdf': [{'Start date': '6th March 2022',\n",
              "   'End date': '6th March 2023'}],\n",
              " 'policy_52.pdf': [{'Start date': '31st May 2022',\n",
              "   'End date': '30th May 2023'}],\n",
              " 'policy_100.pdf': [{'Start date': '1st January 2021',\n",
              "   'End date': '1st January 2022'},\n",
              "  {'Start date': '1st January 2021', 'End date': '1st January 2022'}],\n",
              " 'policy_27.pdf': [{'Start date': '1st October 2022',\n",
              "   'End date': '30th September 2023'},\n",
              "  {'Start date': '1st October 2022', 'End date': '30th September 2023'}],\n",
              " 'policy_24.pdf': [{'Start date': '01 February 2022',\n",
              "   'End date': '31 January 2023'},\n",
              "  {'Start date': '01 February 2022', 'End date': '31 January 2023'}],\n",
              " 'policy_4.pdf': ['Start date: 01/12/2020 End date: 01/12/2020'],\n",
              " 'policy_30.pdf': [{'Start date': '30th June 2022',\n",
              "   'End date': '30th June 2023'}],\n",
              " 'policy_33.pdf': ['Start date: 1/12/2022 End date: 30/11/2023',\n",
              "  'No dates found'],\n",
              " 'policy_29.pdf': [{'Start date': '20th February 2022',\n",
              "   'End date': '20th February 2023'}],\n",
              " 'policy_79.pdf': ['Start date: 30/06/2022 End date: 30/06/2023'],\n",
              " 'policy_56.pdf': [{'Start date': '27 May 2022', 'End date': '26 May 2023'}],\n",
              " 'policy_92.pdf': [{'Start date': '17th August 2017',\n",
              "   'End date': '11th December 2017'}],\n",
              " 'policy_32.pdf': ['Start date: 1/12/2021 End date: 30/11/2022',\n",
              "  'No dates found'],\n",
              " 'policy_1.pdf': [{'Start date': '31st March 2021',\n",
              "   'End date': '30th March 2022'}],\n",
              " 'policy_69.pdf': ['Start date: 15th July 2022 End date: 15th July 2023'],\n",
              " 'policy_64.pdf': ['Start date: 01/04/2022 End date: 31/03/2023',\n",
              "  'No dates found',\n",
              "  'No dates found'],\n",
              " 'policy_35.pdf': [{'Start date': '01 April 2022',\n",
              "   'End date': '31 March 2023'}],\n",
              " 'policy_8.pdf': [{'Start date': '21 April 2021',\n",
              "   'End date': '20 April 2022'}],\n",
              " 'policy_20.pdf': [{'Start date': '30th November 2022',\n",
              "   'End date': '31st May 2024'}],\n",
              " 'policy_9.pdf': [{'Start date': '1 June 2022', 'End date': '1 December 2023'},\n",
              "  {'Start date': '1 June 2022', 'End date': '1 December 2023'},\n",
              "  {'Start date': '1 June 2022', 'End date': '1 December 2023'}],\n",
              " 'policy_13.pdf': ['Start date: January 1 2021 End date: January 1 2022'],\n",
              " 'policy_66.pdf': [{'Start date': '1st September 2021',\n",
              "   'End date': '1st September 2022'},\n",
              "  {'Start date': '1st September 2021', 'End date': '1st September 2022'}],\n",
              " 'policy_63.pdf': ['Start date: 31 May 2022 End date: 31 May 2023',\n",
              "  'Start date: 31 May 2021 End date: 31 May 2022'],\n",
              " 'policy_39.pdf': ['Start date: 31st March 2022 End date: 31st March 2023']}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}